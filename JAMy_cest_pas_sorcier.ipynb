{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "544d4537",
   "metadata": {},
   "source": [
    "# JAMy_cest_pas_sorcier Project\n",
    "### Alexandre Flachs, Marie Giot & Jeanne Szpirer\n",
    "\n",
    "#### Participation to \"Flu Shot Learning: Predict H1N1 and Seasonal Flu Vaccines\" competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bdd6e7",
   "metadata": {},
   "source": [
    "First we need to charge all the data (training set features, test set features and training set labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49836f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set features\n",
    "training_set_features <- read.csv(\"training_set_features.csv\", stringsAsFactors = T)\n",
    "dim(training_set_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set features\n",
    "test_set_features <- read.csv(\"test_set_features.csv\", stringsAsFactors = T)\n",
    "dim(test_set_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aad7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set labels\n",
    "training_set_labels <- read.csv(\"training_set_labels.csv\", stringsAsFactors = T)\n",
    "dim(training_set_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e7ee02",
   "metadata": {},
   "source": [
    "We can see that the training features set and the training labels set has the same amount of lines, this is a first good sign because it means that we have an \"answer\" for every training line.\n",
    "Then we can check if there is any missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c3c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First method\n",
    "dim(na.omit(training_set_features))\n",
    "dim(na.omit(test_set_features))\n",
    "dim(na.omit(training_set_labels))\n",
    "\n",
    "# Second method (when TRUE, there is at least one missing value in the column)\n",
    "apply(is.na(training_set_features),2,any)\n",
    "apply(is.na(test_set_features),2,any)\n",
    "apply(is.na(training_set_labels),2,any)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53901722",
   "metadata": {},
   "source": [
    "There are missing values in the features sets(13 506 lines instead of 26 707 in training set and 13 513 lines instead of 26 708 in test set). We can replace them with mean values like we did in the practicals. We are first going to transform the factor values into numerical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fdd5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut aussi regarder si certaines colonnes n'ont vraiment quasi aucune valeur, dans ce cas, ça vaut pas vraiment la peine de garder\n",
    "sapply(training_set_features, function(x) sum(is.na(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5687e4e",
   "metadata": {},
   "source": [
    "Quand même 12 274 valeurs manquantes pour \"health_insurance\" mais ça peut fort impacter le fait que le patient ait reçu une dose de vaccin. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad569f23",
   "metadata": {},
   "source": [
    "### Je le fais d'abord avec le training_set_features mais il faudra appliquer pareil au test_set_features je pense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a80089",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(training_set_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sapply(training_set_features[1,],class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e521d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_variables<-which(sapply(training_set_features[1,],class)==\"factor\")\n",
    "factor_variables\n",
    "data_factor<-training_set_features[,factor_variables]\n",
    "dim(data_factor)\n",
    "data_preprocessed<-training_set_features[,-factor_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b44b7d",
   "metadata": {},
   "source": [
    "We can choose several variables that should influence the output variables in our opinion and according to the scientific articles we have read.\n",
    "### Pas hésiter à les mettre quand on en aura hihi\n",
    "Mais selon moi, \"marital_status\", \"rent_or_own\", \"education\" et \"employment_status\" devraient pas trop influencer. Et \"employment_industry\" & \"employment_occupation\" sont des random short strings hyper nombreux donc pas convaincue que ça soit très utile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aabbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need dummies package to transform string values with one-hot-encoding.\n",
    "install.packages('dummies')\n",
    "library(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000334fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We keep only some factor variables\n",
    "variables_to_keep<-c(\"age_group\",\"race\",\"sex\",\"income_poverty\",\"hhs_geo_region\",\"census_msa\")\n",
    "data_factor_onehot <- dummy.data.frame(data_factor[,variables_to_keep], sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b5d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(data_factor_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552763f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_factor_onehot[1:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccce21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed_extended<-cbind(data_preprocessed,data_factor_onehot)\n",
    "dim(data_preprocessed_extended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b64b2c",
   "metadata": {},
   "source": [
    "On peut passer au traitement des missing values. Pour le moment, j'implémente la même chose que dans les TP (on remplace par la mean value) mais on peut 100% faire plus de recherches et remplacer par autre chose. J'ai vu que la median value était souvent utilisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e0f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_na_with_mean_value<-function(vec) {\n",
    "    mean_vec<-mean(vec,na.rm=T)\n",
    "    vec[is.na(vec)]<-mean_vec\n",
    "    vec\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5253dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed_extended<-data.frame(apply(data_preprocessed_extended,2,replace_na_with_mean_value))\n",
    "summary(data_preprocessed_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a084d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(na.omit(data_preprocessed_extended))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7cc4cf",
   "metadata": {},
   "source": [
    "A ce stade, on a un set de data avec seulement des variables numériques qui ont du sens d'être là (selon moi hihi) et plus de missing values donc il manque surtout feature engineering. On pourra ensuite faire feature selection avec une mesure de la corrélation entre input et output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
