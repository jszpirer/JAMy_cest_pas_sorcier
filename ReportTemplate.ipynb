{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO-F-422 -  Statistical Foundations of Machine Learning \n",
    "\n",
    "### Alexandre Flachs - __[alexandre.flachs@ulb.be](mailto:alexandre.flachs@ulb.be) - Student ID 474748__\n",
    "### Marie Giot - __[marie.giot@ulb.be](mailto:marie.giot@ulb.be) - Student ID 474915__\n",
    "### Jeanne Szpirer - __[jeanne.szpirer@ulb.be](mailto:jeanne.szpirer@ulb.be) - Student ID 477286__\n",
    "\n",
    "### Video presentation: www.youtube.com/abcd1234\n",
    "\n",
    "## Flu Shot Learning: Predict H1N1 and Seasonal Flu Vaccines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ajouter du texte d'intro avec jolies images ?* ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "Before working any model we need to preprocess the data to make it usefull. This pipeline in divided intro three parts :\n",
    "1. **Missing value imputation** : Replace missing values, possibly using other known values\n",
    "2. **Feature engineering** : Define useful features from available ones. \n",
    "3. **Feature selection** : Some features might be useless or give wrong indications to the model, we might need to remove some features.\n",
    "\n",
    "Let's start by importing our data, then develop each of the above parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>26707</li><li>36</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 26707\n",
       "\\item 36\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 26707\n",
       "2. 36\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 26707    36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>26708</li><li>36</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 26708\n",
       "\\item 36\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 26708\n",
       "2. 36\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 26708    36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>26707</li><li>3</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 26707\n",
       "\\item 3\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 26707\n",
       "2. 3\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 26707     3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training set features\n",
    "training_set_features <- read.csv(\"training_set_features.csv\", stringsAsFactors = T, na.strings = c(\"NA\", \"\"))\n",
    "dim(training_set_features)\n",
    "\n",
    "# Test set features\n",
    "test_set_features <- read.csv(\"test_set_features.csv\", stringsAsFactors = T, na.strings = c(\"NA\", \"\"))\n",
    "dim(test_set_features)\n",
    "\n",
    "# Training set labels\n",
    "training_set_labels <- read.csv(\"training_set_labels.csv\", stringsAsFactors = T, na.strings = c(\"NA\", \"\"))\n",
    "dim(training_set_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the training features set and the training labels set has the same amount of lines, this is a first good sign because it means that we have an \"answer\" for every training line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing value imputation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We summarize our data before doing any work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " respondent_id    h1n1_concern   h1n1_knowledge  behavioral_antiviral_meds\n",
       " Min.   :    0   Min.   :0.000   Min.   :0.000   Min.   :0.00000          \n",
       " 1st Qu.: 6676   1st Qu.:1.000   1st Qu.:1.000   1st Qu.:0.00000          \n",
       " Median :13353   Median :2.000   Median :1.000   Median :0.00000          \n",
       " Mean   :13353   Mean   :1.618   Mean   :1.263   Mean   :0.04884          \n",
       " 3rd Qu.:20030   3rd Qu.:2.000   3rd Qu.:2.000   3rd Qu.:0.00000          \n",
       " Max.   :26706   Max.   :3.000   Max.   :2.000   Max.   :1.00000          \n",
       "                 NA's   :92      NA's   :116     NA's   :71               \n",
       " behavioral_avoidance behavioral_face_mask behavioral_wash_hands\n",
       " Min.   :0.0000       Min.   :0.00000      Min.   :0.0000       \n",
       " 1st Qu.:0.0000       1st Qu.:0.00000      1st Qu.:1.0000       \n",
       " Median :1.0000       Median :0.00000      Median :1.0000       \n",
       " Mean   :0.7256       Mean   :0.06898      Mean   :0.8256       \n",
       " 3rd Qu.:1.0000       3rd Qu.:0.00000      3rd Qu.:1.0000       \n",
       " Max.   :1.0000       Max.   :1.00000      Max.   :1.0000       \n",
       " NA's   :208          NA's   :19           NA's   :42           \n",
       " behavioral_large_gatherings behavioral_outside_home behavioral_touch_face\n",
       " Min.   :0.0000              Min.   :0.0000          Min.   :0.0000       \n",
       " 1st Qu.:0.0000              1st Qu.:0.0000          1st Qu.:0.0000       \n",
       " Median :0.0000              Median :0.0000          Median :1.0000       \n",
       " Mean   :0.3586              Mean   :0.3373          Mean   :0.6773       \n",
       " 3rd Qu.:1.0000              3rd Qu.:1.0000          3rd Qu.:1.0000       \n",
       " Max.   :1.0000              Max.   :1.0000          Max.   :1.0000       \n",
       " NA's   :87                  NA's   :82              NA's   :128          \n",
       " doctor_recc_h1n1 doctor_recc_seasonal chronic_med_condition\n",
       " Min.   :0.0000   Min.   :0.0000       Min.   :0.0000       \n",
       " 1st Qu.:0.0000   1st Qu.:0.0000       1st Qu.:0.0000       \n",
       " Median :0.0000   Median :0.0000       Median :0.0000       \n",
       " Mean   :0.2203   Mean   :0.3297       Mean   :0.2833       \n",
       " 3rd Qu.:0.0000   3rd Qu.:1.0000       3rd Qu.:1.0000       \n",
       " Max.   :1.0000   Max.   :1.0000       Max.   :1.0000       \n",
       " NA's   :2160     NA's   :2160         NA's   :971          \n",
       " child_under_6_months health_worker    health_insurance\n",
       " Min.   :0.0000       Min.   :0.0000   Min.   :0.00    \n",
       " 1st Qu.:0.0000       1st Qu.:0.0000   1st Qu.:1.00    \n",
       " Median :0.0000       Median :0.0000   Median :1.00    \n",
       " Mean   :0.0826       Mean   :0.1119   Mean   :0.88    \n",
       " 3rd Qu.:0.0000       3rd Qu.:0.0000   3rd Qu.:1.00    \n",
       " Max.   :1.0000       Max.   :1.0000   Max.   :1.00    \n",
       " NA's   :820          NA's   :804      NA's   :12274   \n",
       " opinion_h1n1_vacc_effective opinion_h1n1_risk opinion_h1n1_sick_from_vacc\n",
       " Min.   :1.000               Min.   :1.000     Min.   :1.000              \n",
       " 1st Qu.:3.000               1st Qu.:1.000     1st Qu.:1.000              \n",
       " Median :4.000               Median :2.000     Median :2.000              \n",
       " Mean   :3.851               Mean   :2.343     Mean   :2.358              \n",
       " 3rd Qu.:5.000               3rd Qu.:4.000     3rd Qu.:4.000              \n",
       " Max.   :5.000               Max.   :5.000     Max.   :5.000              \n",
       " NA's   :391                 NA's   :388       NA's   :395                \n",
       " opinion_seas_vacc_effective opinion_seas_risk opinion_seas_sick_from_vacc\n",
       " Min.   :1.000               Min.   :1.000     Min.   :1.000              \n",
       " 1st Qu.:4.000               1st Qu.:2.000     1st Qu.:1.000              \n",
       " Median :4.000               Median :2.000     Median :2.000              \n",
       " Mean   :4.026               Mean   :2.719     Mean   :2.118              \n",
       " 3rd Qu.:5.000               3rd Qu.:4.000     3rd Qu.:4.000              \n",
       " Max.   :5.000               Max.   :5.000     Max.   :5.000              \n",
       " NA's   :462                 NA's   :514       NA's   :537                \n",
       "         age_group               education                    race      \n",
       " 18 - 34 Years:5215   < 12 Years      : 2363   Black            : 2118  \n",
       " 35 - 44 Years:3848   12 Years        : 5797   Hispanic         : 1755  \n",
       " 45 - 54 Years:5238   College Graduate:10097   Other or Multiple: 1612  \n",
       " 55 - 64 Years:5563   Some College    : 7043   White            :21222  \n",
       " 65+ Years    :6843   NA's            : 1407                            \n",
       "                                                                        \n",
       "                                                                        \n",
       "     sex                          income_poverty      marital_status \n",
       " Female:15858   <= $75,000, Above Poverty:12777   Married    :13555  \n",
       " Male  :10849   > $75,000                : 6810   Not Married:11744  \n",
       "                Below Poverty            : 2697   NA's       : 1408  \n",
       "                NA's                     : 4423                      \n",
       "                                                                     \n",
       "                                                                     \n",
       "                                                                     \n",
       " rent_or_own           employment_status  hhs_geo_region\n",
       " Own :18736   Employed          :13560   lzgpxyit:4297  \n",
       " Rent: 5929   Not in Labor Force:10231   fpwskwrf:3265  \n",
       " NA's: 2042   Unemployed        : 1453   qufhixun:3102  \n",
       "              NA's              : 1463   oxchjgsf:2859  \n",
       "                                         kbazzjca:2858  \n",
       "                                         bhuqouqj:2846  \n",
       "                                         (Other) :7480  \n",
       "                    census_msa    household_adults household_children\n",
       " MSA, Not Principle  City:11645   Min.   :0.0000   Min.   :0.0000    \n",
       " MSA, Principle City     : 7864   1st Qu.:0.0000   1st Qu.:0.0000    \n",
       " Non-MSA                 : 7198   Median :1.0000   Median :0.0000    \n",
       "                                  Mean   :0.8865   Mean   :0.5346    \n",
       "                                  3rd Qu.:1.0000   3rd Qu.:1.0000    \n",
       "                                  Max.   :3.0000   Max.   :3.0000    \n",
       "                                  NA's   :249      NA's   :249       \n",
       " employment_industry employment_occupation\n",
       " fcxhlnwr: 2468      xtkaffoo: 1778       \n",
       " wxleyezf: 1804      mxkfnird: 1509       \n",
       " ldnlellj: 1231      emcorrxb: 1270       \n",
       " pxcmvdjn: 1037      cmhcxjea: 1247       \n",
       " atmlpfrs:  926      xgwztkwe: 1082       \n",
       " (Other) : 5911      (Other) : 6351       \n",
       " NA's    :13330      NA's    :13470       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(training_set_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have many missing values, in most features. We can compare the number of lines left if we remove any line containing any missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set :  26707 -> 6437 \n",
      "Test set     :  26708 -> 6499 \n",
      "Training labs:  26707 -> 26707"
     ]
    }
   ],
   "source": [
    "# First method\n",
    "cat(\"Training set : \", dim(training_set_features)[1], \"->\", dim(na.omit(training_set_features))[1], \"\\n\")\n",
    "cat(\"Test set     : \", dim(test_set_features)[1], \"->\", dim(na.omit(test_set_features))[1], \"\\n\")\n",
    "cat(\"Training labs: \", dim(training_set_labels)[1], \"->\", dim(na.omit(training_set_labels))[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least no line from the training labels misses any value, we can thus use every entry from the training set for both targets.\n",
    "Counting the number of missing value per feature allows us to see if some of the could be useless. The health insurance, employment occupation and employment industry lines are the emptiest (almost half of the lines miss this data) but by intuition this might be a huge factor in the vaccination decision so we keep it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      employment_occupation         employment_industry \n",
      "                      13470                       13330 \n",
      "           health_insurance              income_poverty \n",
      "                      12274                        4423 \n",
      "           doctor_recc_h1n1        doctor_recc_seasonal \n",
      "                       2160                        2160 \n",
      "                rent_or_own           employment_status \n",
      "                       2042                        1463 \n",
      "             marital_status                   education \n",
      "                       1408                        1407 \n",
      "      chronic_med_condition        child_under_6_months \n",
      "                        971                         820 \n",
      "              health_worker opinion_seas_sick_from_vacc \n",
      "                        804                         537 \n",
      "          opinion_seas_risk opinion_seas_vacc_effective \n",
      "                        514                         462 \n",
      "opinion_h1n1_sick_from_vacc opinion_h1n1_vacc_effective \n",
      "                        395                         391 \n",
      "          opinion_h1n1_risk            household_adults \n",
      "                        388                         249 \n",
      "         household_children        behavioral_avoidance \n",
      "                        249                         208 \n",
      "      behavioral_touch_face              h1n1_knowledge \n",
      "                        128                         116 \n",
      "               h1n1_concern behavioral_large_gatherings \n",
      "                         92                          87 \n",
      "    behavioral_outside_home   behavioral_antiviral_meds \n",
      "                         82                          71 \n",
      "      behavioral_wash_hands        behavioral_face_mask \n",
      "                         42                          19 \n",
      "              respondent_id                   age_group \n",
      "                          0                           0 \n",
      "                       race                         sex \n",
      "                          0                           0 \n",
      "             hhs_geo_region                  census_msa \n",
      "                          0                           0 \n"
     ]
    }
   ],
   "source": [
    "# On peut aussi regarder si certaines colonnes n'ont vraiment quasi aucune valeur, dans ce cas, ça vaut pas vraiment la peine de garder\n",
    "a <- sapply(training_set_features, function(x) sum(is.na(x)))\n",
    "print(a[order(a, decreasing=T)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we remove these fields ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set :  26707 -> 19642 \n",
      "Test set     :  26708 -> 19592 \n",
      "Training labels:  26707 -> 26707"
     ]
    }
   ],
   "source": [
    "useful_nas <- which(sapply(test_set_features, function(x) sum(is.na(x))) > 10000)\n",
    "\n",
    "cat(\"Training set : \",\n",
    "    dim(training_set_features[,-useful_nas])[1], \"->\",\n",
    "    dim(na.omit(training_set_features[,-useful_nas]))[1], \"\\n\")\n",
    "cat(\"Test set     : \", dim(test_set_features[,-useful_nas])[1], \"->\",\n",
    "    dim(na.omit(test_set_features[,-useful_nas]))[1], \"\\n\")\n",
    "cat(\"Training labels: \", dim(training_set_labels)[1], \"->\", dim(na.omit(training_set_labels))[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are much less lines containing missing values. We will thus manage the three most missed fields differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation of missing numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation will be the same for training and testing so we merge them\n",
    "features_set <- rbind(training_set_features, test_set_features)\n",
    "\n",
    "\n",
    "# Note the indexes of each dataset to get them back after\n",
    "tr_indexes <- 1:nrow(training_set_features)\n",
    "ts_indexes <- (nrow(training_set_features)+1):(nrow(training_set_features) + nrow(test_set_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integer encoding of some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'18 - 34 Years'</li><li>'35 - 44 Years'</li><li>'45 - 54 Years'</li><li>'55 - 64 Years'</li><li>'65+ Years'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '18 - 34 Years'\n",
       "\\item '35 - 44 Years'\n",
       "\\item '45 - 54 Years'\n",
       "\\item '55 - 64 Years'\n",
       "\\item '65+ Years'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '18 - 34 Years'\n",
       "2. '35 - 44 Years'\n",
       "3. '45 - 54 Years'\n",
       "4. '55 - 64 Years'\n",
       "5. '65+ Years'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"18 - 34 Years\" \"35 - 44 Years\" \"45 - 54 Years\" \"55 - 64 Years\"\n",
       "[5] \"65+ Years\"    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'&lt; 12 Years'</li><li>'12 Years'</li><li>'College Graduate'</li><li>'Some College'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '< 12 Years'\n",
       "\\item '12 Years'\n",
       "\\item 'College Graduate'\n",
       "\\item 'Some College'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '&lt; 12 Years'\n",
       "2. '12 Years'\n",
       "3. 'College Graduate'\n",
       "4. 'Some College'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"< 12 Years\"       \"12 Years\"         \"College Graduate\" \"Some College\"    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'&lt;= $75,000, Above Poverty'</li><li>'&gt; $75,000'</li><li>'Below Poverty'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '<= \\$75,000, Above Poverty'\n",
       "\\item '> \\$75,000'\n",
       "\\item 'Below Poverty'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '&lt;= $75,000, Above Poverty'\n",
       "2. '&gt; $75,000'\n",
       "3. 'Below Poverty'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"<= $75,000, Above Poverty\" \"> $75,000\"                \n",
       "[3] \"Below Poverty\"            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li><span style=white-space:pre-wrap>'MSA, Not Principle  City'</span></li><li>'MSA, Principle City'</li><li>'Non-MSA'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'MSA, Not Principle  City'\n",
       "\\item 'MSA, Principle City'\n",
       "\\item 'Non-MSA'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. <span style=white-space:pre-wrap>'MSA, Not Principle  City'</span>\n",
       "2. 'MSA, Principle City'\n",
       "3. 'Non-MSA'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"MSA, Not Principle  City\" \"MSA, Principle City\"     \n",
       "[3] \"Non-MSA\"                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "levels(features_set[, \"age_group\"])\n",
    "levels(features_set[, \"age_group\"]) <- 0:4\n",
    "features_set[, \"age_group\"] <- as.numeric(features_set[, \"age_group\"])\n",
    "features_set[, \"age_group\"] <- (features_set[, \"age_group\"] - 1)/4\n",
    "\n",
    "levels(features_set[, \"education\"])\n",
    "levels(features_set[, \"education\"]) <- 0:3\n",
    "features_set[, \"education\"] <- as.numeric(features_set[, \"education\"])\n",
    "features_set[, \"education\"] <- (features_set[, \"education\"] - 1)/3\n",
    "\n",
    "levels(features_set[, \"income_poverty\"])\n",
    "levels(features_set[, \"income_poverty\"]) <- c(1, 2, 0)\n",
    "features_set[, \"income_poverty\"] <- as.numeric(features_set[, \"income_poverty\"])\n",
    "features_set[, \"income_poverty\"] <- (features_set[, \"income_poverty\"] - 1)/2\n",
    "\n",
    "levels(features_set[, \"census_msa\"])\n",
    "levels(features_set[, \"census_msa\"]) <- c(1, 2, 0)\n",
    "features_set[, \"census_msa\"] <- as.numeric(features_set[, \"census_msa\"])\n",
    "features_set[, \"census_msa\"] <- (features_set[, \"census_msa\"] - 1)/2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non negative matrix factorization based imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non negative matrix factorization is a procedure which consists of approximating a matrix with non negative values as the product of two matrices having smaller dimensions. More formally, a matrix $M$ of dimension $m\\times n$ is decomposed into two matrices $W$ and $H$ of dimensions $m\\times p$ and $p\\times n$ respectively such that $M \\approx WH$.\n",
    "\n",
    "More details concerning the imputation method can be found here https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8510447/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PseudoCode :\n",
    "\n",
    "```pseudocode\n",
    "Consider M of dim m x n having missing values\n",
    "Fix N > 0\n",
    "Normalize M and replace NAs using mean imputation\n",
    "k1 <- floor(max(abs(rank(M) - N/2), 1))\n",
    "kN = min(abs(rX + N/2), m, n)\n",
    "\n",
    "# Compute approximation\n",
    "initialize X array of size kN-k1+1\n",
    "for k in 1...kN-k1+1 do\n",
    "    Compute the nNMF of M on non missing values and store the result in X[k]\n",
    "\n",
    "## Based on all X[k], reconstruct M\n",
    "# Weights based only on non missing values of M\n",
    "initialize d array of size kN-k1+1\n",
    "for k in 1...kN-k1+1 do\n",
    "    Compute d[k] = sum(X_ij - M_ij)/ nb_nonNA\n",
    "\n",
    "# Reconstruct\n",
    "Initialize divisor=0, M_hat of 0 with same dim as M\n",
    "for k in 1...kN-k1+1 do\n",
    "    M_hat += exp(-d[k])*X[k]\n",
    "    denum += exp(-d[k])\n",
    "M_hat <- M_hat/denum\n",
    "```\n",
    "\n",
    "\n",
    "After these steps, M_hat does not contain missing values and the imputation is based on local and global information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ggplot2\n",
      "\n",
      "Loading required package: lattice\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  h1n1_concern    h1n1_knowledge   behavioral_antiviral_meds\n",
       " Min.   :0.0000   Min.   :0.0000   Min.   :0.00000          \n",
       " 1st Qu.:0.3333   1st Qu.:0.5000   1st Qu.:0.00000          \n",
       " Median :0.6667   Median :0.5000   Median :0.00000          \n",
       " Mean   :0.5403   Mean   :0.6321   Mean   :0.04924          \n",
       " 3rd Qu.:0.6667   3rd Qu.:1.0000   3rd Qu.:0.00000          \n",
       " Max.   :1.0000   Max.   :1.0000   Max.   :1.00000          \n",
       " NA's   :177      NA's   :238      NA's   :150              \n",
       " behavioral_avoidance behavioral_face_mask behavioral_wash_hands\n",
       " Min.   :0.0000       Min.   :0.00000      Min.   :0.0000       \n",
       " 1st Qu.:0.0000       1st Qu.:0.00000      1st Qu.:1.0000       \n",
       " Median :1.0000       Median :0.00000      Median :1.0000       \n",
       " Mean   :0.7277       Mean   :0.06913      Mean   :0.8258       \n",
       " 3rd Qu.:1.0000       3rd Qu.:0.00000      3rd Qu.:1.0000       \n",
       " Max.   :1.0000       Max.   :1.00000      Max.   :1.0000       \n",
       " NA's   :421          NA's   :38           NA's   :82           \n",
       " behavioral_large_gatherings behavioral_outside_home behavioral_touch_face\n",
       " Min.   :0.0000              Min.   :0.0000          Min.   :0.0000       \n",
       " 1st Qu.:0.0000              1st Qu.:0.0000          1st Qu.:0.0000       \n",
       " Median :0.0000              Median :0.0000          Median :1.0000       \n",
       " Mean   :0.3551              Mean   :0.3373          Mean   :0.6805       \n",
       " 3rd Qu.:1.0000              3rd Qu.:1.0000          3rd Qu.:1.0000       \n",
       " Max.   :1.0000              Max.   :1.0000          Max.   :1.0000       \n",
       " NA's   :159                 NA's   :164             NA's   :256          \n",
       " doctor_recc_h1n1 doctor_recc_seasonal chronic_med_condition\n",
       " Min.   :0.000    Min.   :0.000        Min.   :0.0000       \n",
       " 1st Qu.:0.000    1st Qu.:0.000        1st Qu.:0.0000       \n",
       " Median :0.000    Median :0.000        Median :0.0000       \n",
       " Mean   :0.221    Mean   :0.332        Mean   :0.2821       \n",
       " 3rd Qu.:0.000    3rd Qu.:1.000        3rd Qu.:1.0000       \n",
       " Max.   :1.000    Max.   :1.000        Max.   :1.0000       \n",
       " NA's   :4320     NA's   :4320         NA's   :1903         \n",
       " child_under_6_months health_worker    opinion_h1n1_vacc_effective\n",
       " Min.   :0.0000       Min.   :0.0000   Min.   :0.0000             \n",
       " 1st Qu.:0.0000       1st Qu.:0.0000   1st Qu.:0.5000             \n",
       " Median :0.0000       Median :0.0000   Median :0.7500             \n",
       " Mean   :0.0845       Mean   :0.1117   Mean   :0.7119             \n",
       " 3rd Qu.:0.0000       3rd Qu.:0.0000   3rd Qu.:1.0000             \n",
       " Max.   :1.0000       Max.   :1.0000   Max.   :1.0000             \n",
       " NA's   :1633         NA's   :1593     NA's   :789                \n",
       " opinion_h1n1_risk opinion_h1n1_sick_from_vacc opinion_seas_vacc_effective\n",
       " Min.   :0.0000    Min.   :0.0000              Min.   :0.0000             \n",
       " 1st Qu.:0.0000    1st Qu.:0.0000              1st Qu.:0.7500             \n",
       " Median :0.2500    Median :0.2500              Median :0.7500             \n",
       " Mean   :0.3337    Mean   :0.3398              Mean   :0.7564             \n",
       " 3rd Qu.:0.7500    3rd Qu.:0.7500              3rd Qu.:1.0000             \n",
       " Max.   :1.0000    Max.   :1.0000              Max.   :1.0000             \n",
       " NA's   :768       NA's   :770                 NA's   :914                \n",
       " opinion_seas_risk opinion_seas_sick_from_vacc   age_group     \n",
       " Min.   :0.0000    Min.   :0.0000              Min.   :0.0000  \n",
       " 1st Qu.:0.2500    1st Qu.:0.0000              1st Qu.:0.2500  \n",
       " Median :0.2500    Median :0.2500              Median :0.5000  \n",
       " Mean   :0.4285    Mean   :0.2827              Mean   :0.5445  \n",
       " 3rd Qu.:0.7500    3rd Qu.:0.7500              3rd Qu.:1.0000  \n",
       " Max.   :1.0000    Max.   :1.0000              Max.   :1.0000  \n",
       " NA's   :1013      NA's   :1058                                \n",
       "   education      income_poverty    census_msa    household_adults\n",
       " Min.   :0.0000   Min.   :0.000   Min.   :0.000   Min.   :0.0000  \n",
       " 1st Qu.:0.3333   1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.0000  \n",
       " Median :0.6667   Median :0.000   Median :0.500   Median :0.3333  \n",
       " Mean   :0.6221   Mean   :0.272   Mean   :0.412   Mean   :0.2968  \n",
       " 3rd Qu.:1.0000   3rd Qu.:0.500   3rd Qu.:1.000   3rd Qu.:0.3333  \n",
       " Max.   :1.0000   Max.   :1.000   Max.   :1.000   Max.   :1.0000  \n",
       " NA's   :2814     NA's   :8920                    NA's   :474     \n",
       " household_children\n",
       " Min.   :0.0000    \n",
       " 1st Qu.:0.0000    \n",
       " Median :0.0000    \n",
       " Mean   :0.1797    \n",
       " 3rd Qu.:0.3333    \n",
       " Max.   :1.0000    \n",
       " NA's   :474       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(NMFN)\n",
    "\n",
    "# We work only on the columns of numeric type\n",
    "numeric_variables_idx<-which(sapply(features_set[1,],class)!=\"factor\")\n",
    "numeric_variables_idx <- numeric_variables_idx[-c(1, 16)] # Remove resp ID and health insur\n",
    "\n",
    "# We need to normalize this data to use efficient nNMF\n",
    "library(\"caret\")\n",
    "\n",
    "ss <- preProcess(as.data.frame(features_set[, numeric_variables_idx]), method=c(\"range\"))\n",
    "features_set[,numeric_variables_idx] <- predict(ss, as.data.frame(features_set[, numeric_variables_idx]))\n",
    "summary(features_set[, numeric_variables_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function that will compute nmf\n",
    "nfm_mult_upd <- function(R, K, missing_idx, maxit=800, eps=2.2204e-16) {\n",
    "    # Using weighted multiplicative rule Zhu 2016\n",
    "    # init random W and H\n",
    "    print(paste(\"[INFO] : NMF with k=\", K))\n",
    "    R <- as.matrix(R)\n",
    "    I <- dim(R)[1]\n",
    "    J <- dim(R)[2]\n",
    "    M <- matrix(1, nrow = dim(R)[1], ncol = dim(R)[2])\n",
    "    M[missing_idx] <- 0\n",
    "    X <- R # Store original R\n",
    "    R <- R*M\n",
    "    W <- matrix(runif(I*K), nrow = I, ncol = K)\n",
    "    H <- matrix(runif(K*J), nrow = K, ncol = J)\n",
    "    \n",
    "    n <- 0\n",
    "    d1 <- 1000\n",
    "    d2 <- 1000\n",
    "    while(n < maxit && !(d1 < eps && d2 < eps)) {\n",
    "        if (n %% 100 == 0) {\n",
    "            print(paste(\"[INFO] : iter\", n, \" Relative error is :\", distance2(X, W%*%H)/distance2(X, R*0)))\n",
    "        }\n",
    "        newH <- H* (t(W) %*% R) / (t(W) %*% W %*% H)\n",
    "        newW <- W*(R %*% t(newH)) / ((W %*% newH) %*% t(newH))\n",
    "        \n",
    "        d1 <- distance2(newH, H)\n",
    "        d2 <- distance2(newW, W)\n",
    "        \n",
    "        H <- newH\n",
    "        W <- newW\n",
    "        n <- n+1\n",
    "    }\n",
    "    \n",
    "    Res <- W%*%H\n",
    "    #Res[missing_idx] <- X[missing_idx]\n",
    "    nmf <- list(\"res\"=Res, \"dst\"=distance2(R, Res)/distance2(R, 0))\n",
    "    return(nmf)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: initialize by defining N and replace NAs by mean\n",
    "N <- 4\n",
    "\n",
    "replace_na_with_mean_value<-function(vec) {\n",
    "    mean_vec <- mean(as.numeric(vec), na.rm=TRUE)\n",
    "    vec[is.na(vec)]<-mean_vec\n",
    "    vec\n",
    "}\n",
    "\n",
    "X<-data.frame(apply(features_set[, numeric_variables_idx], MARGIN=2, replace_na_with_mean_value))\n",
    "miss_idx = which(is.na(features_set[,numeric_variables_idx]), arr.ind = T)\n",
    "non_miss_idx <- which(!is.na(features_set[,numeric_variables_idx]), arr.ind = T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: nNMF for k=k1 to K=kN with masking missing values\n",
    "library(Matrix) # For rankMatrix \n",
    "rX <- rankMatrix(X)\n",
    "k1 = floor(max(abs(rX - N/2), 1))\n",
    "kN = min(abs(rX + N/2), dim(X)[1], dim(X)[2])\n",
    "\n",
    "X_hat = array(0, dim = c(kN-k1+1, nrow(X), ncol(X)))\n",
    "dim(X_hat)\n",
    "for (K in k1:kN) {\n",
    "    # compute NMF\n",
    "    nmf <- nfm_mult_upd(X, K, missing_idx = miss_idx, maxit=800)\n",
    "    print(paste(\"Computed nmf, final dist is\", nmf$dst))\n",
    "    X_hat[K-k1+1,,] <- nmf$res\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: weighted reconstruction\n",
    "d = array(0, dim = c(kN-k1+1))\n",
    "for (K in 1:(kN-k1+1)) {\n",
    "    # Reconstruction error based on non missing values\n",
    "    d[K] <- sum(abs(X_hat[K,,][non_miss_idx] - X[non_miss_idx]))/nrow(non_miss_idx)\n",
    "}\n",
    "\n",
    "X_hat_f <- matrix(0, nrow = nrow(X), ncol = ncol(X))\n",
    "denum <- 0\n",
    "for (K in 1:(kN-k1+1)) {\n",
    "    # Reconstruction matrix\n",
    "    X_hat_f <- X_hat_f + exp(-d[K])*X_hat[K,,]\n",
    "    denum <- denum + exp(-d[K])\n",
    "}\n",
    "X_hat_f <- X_hat_f / sum(exp(-d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in the feature set\n",
    "X[miss_idx] <- X_hat_f[miss_idx]\n",
    "features_set[, numeric_variables_idx] <- X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we managed numerical variabels we can work on encoding the categorical ones which we did not work on yet.\n",
    "\n",
    "Getting back to the columns containing many missing values, we use one hot encoding and create a category \"missing\", considering that not having this piece of information could be meaning something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_nas <- which(sapply(test_set_features, function(x) sum(is.na(x))) > 10000)\n",
    "\n",
    "library(fastDummies)\n",
    "features_set <- dummy_cols(features_set, \n",
    "                           select_columns = names(useful_nas),\n",
    "                           remove_selected_columns = T)\n",
    "\n",
    "## Change NAs to 0 for the new one hot encoded columns\n",
    "replace_na_with_0<-function(vec) {\n",
    "    vec[is.na(vec)]<-0\n",
    "    vec\n",
    "}\n",
    "\n",
    "useful_nas_feat_idx <- c(grep(\"health_insurance_*\", colnames(features_set)))\n",
    "useful_nas_feat_idx <- c(useful_nas_feat_idx, grep(\"employment_industry*\", colnames(features_set)))\n",
    "useful_nas_feat_idx <- c(useful_nas_feat_idx, grep(\"employment_occup*\", colnames(features_set)))\n",
    "\n",
    "features_set[,useful_nas_feat_idx] <- replace_na_with_0(features_set[,useful_nas_feat_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining columns will be treated the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_variables<-which(sapply(features_set[1,],class)==\"factor\")\n",
    "factor_variables\n",
    "factor_col_names <- colnames(factor_variables)\n",
    "\n",
    "features_set_int_encoded <- dummy_cols(features_set,\n",
    "                                       select_columns = factor_col_names,\n",
    "                                       ignore_na = F,\n",
    "                                       remove_selected_columns = T)\n",
    "\n",
    "\n",
    "features_set_int_encoded <- replace_na_with_0(features_set_int_encoded)\n",
    "\n",
    "tr_set_enc <- features_set_int_encoded[tr_indexes,]\n",
    "ts_set_enc <- features_set_int_encoded[ts_indexes,]\n",
    "\n",
    "summary(features_set_int_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A RETIRER ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose several variables that should influence the output variables in our opinion and according to the scientific articles we have read.\n",
    "### Pas hésiter à les mettre quand on en aura hihi\n",
    "Mais selon moi, \"marital_status\", \"rent_or_own\", \"education\" et \"employment_status\" devraient pas trop influencer. Et \"employment_industry\" & \"employment_occupation\" sont des random short strings hyper nombreux donc pas convaincue que ça soit très utile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need dummies package to transform string values with one-hot-encoding.\n",
    "# install.packages('dummies')\n",
    "library(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We keep only some factor variables\n",
    "variables_to_keep<-c(\"age_group\",\"race\",\"sex\",\"income_poverty\",\"hhs_geo_region\",\"census_msa\")\n",
    "data_factor_onehot <- dummy.data.frame(data_factor[,variables_to_keep], sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(data_factor_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_factor_onehot[1:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed_extended<-cbind(data_preprocessed,data_factor_onehot)\n",
    "dim(data_preprocessed_extended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut passer au traitement des missing values. Pour le moment, j'implémente la même chose que dans les TP (on remplace par la mean value) mais on peut 100% faire plus de recherches et remplacer par autre chose. J'ai vu que la median value était souvent utilisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_na_with_mean_value<-function(vec) {\n",
    "    mean_vec<-mean(vec,na.rm=T)\n",
    "    vec[is.na(vec)]<-mean_vec\n",
    "    vec\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed_extended<-data.frame(apply(data_preprocessed_extended,2,replace_na_with_mean_value))\n",
    "summary(data_preprocessed_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(na.omit(data_preprocessed_extended))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ce stade, on a un set de data avec seulement des variables numériques qui ont du sens d'être là (selon moi hihi) et plus de missing values donc il manque surtout feature engineering. On pourra ensuite faire feature selection avec une mesure de la corrélation entre input et output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection\n",
    "\n",
    "## Model 1\n",
    "We are going to use the simple linear model first to see what kind of accuracy we can get. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D'abord on met tout ensemble pour avoir un tableau avec features+labels\n",
    "label_1 <- training_set_labels[,\"h1n1_vaccine\"]\n",
    "label_2 <- training_set_labels[, \"seasonal_vaccine\"]\n",
    "labels <- cbind(h1n1_vaccine=label_1, seasonal_vaccine=label_2)\n",
    "total_train_set <- cbind(data_preprocessed_extended,labels)\n",
    "#total_train_set\n",
    "# On peut lancer le modèle\n",
    "model <- lm(labels~., total_train_set)\n",
    "#model_bis <- lm(h1n1_vaccine+seasonal_vaccine~.-race_White-sex_Male, total_train_set)\n",
    "#model1 <- lm(h1n1_vaccine~.-seasonal_vaccine, total_train_set)\n",
    "#model2 <- lm(seasonal_vaccine~.-h1n1_vaccine, total_train_set)\n",
    "#Y_hat<- predict(model,data_preprocessed_extended)\n",
    "#empirical_error<-mean((Y_hat-labels)^2)\n",
    "#print(paste(\"Empirical error=\",round(empirical_error,digits=4)))\n",
    "#summary(model) #A décommentariser!\n",
    "Y_pred <- predict(model,subset(total_train_set, select=-c(h1n1_vaccine+seasonal_vaccine)))\n",
    "#print(\"La prédiction est :\")\n",
    "#Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_threshold <- ifelse(Y_pred > 0.5, 1, 0)\n",
    "confusion_matrix <- table(Y_threshold,labels)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je pense que c'est bon pour le linear model, il faudra tester avec le set de test et surtout les bonnes features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "Then we use the randomforest package to make another model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"randomForest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"randomForest\")\n",
    "n_trees <- 5\n",
    "n_trees\n",
    "accuracy_vec <- array(0,n_trees)\n",
    "accuracy_vec\n",
    "\n",
    "vaccine_idx <- sample(1:nrow(total_train_set))\n",
    "half_split <- floor(nrow(total_train_set)/2)\n",
    "half_split\n",
    "\n",
    "for (i in 1:n_trees){ print(i)\n",
    "    #3.1 Take the first half of the dataset as a training data set\n",
    "    train_data <- total_train_set[vaccine_idx[1:half_split],]\n",
    "\n",
    "    #3.2 Take the second half of the dataset as a hold out or test data set\n",
    "    test_data <- total_train_set[vaccine_idx[(half_split+1):nrow(total_train_set)],]\n",
    "    \n",
    "    model <- randomForest(x=train_data[,-c(labels)],\n",
    "                          y=as.factor(train_data[,c(labels)]),\n",
    "                          xtest=test_data[,-c(labels)],\n",
    "                          ytest=as.factor(test_data[,c(labels)]),\n",
    "                          ntree=i)\n",
    "    \n",
    "    accuracy_vec[i] = (model$test$confusion[1,1]+model$test$confusion[2,2])/sum(model$test$confusion)\n",
    "    }\n",
    "\n",
    "plot(accuracy_vec,main = \"Number of trees influence\",xlab = \"Nbr of trees\",ylab = \"Classification rate\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ne pas décommenter car pas sûre que ça fonctionne\n",
    "#library(\"randomForest\")\n",
    "# Create the forest.\n",
    "#output.forest <- randomForest(formula=h1n1_vaccine+seasonal_vaccine~., data=total_train_set)\n",
    "\n",
    "# View the forest results.\n",
    "#print(output.forest) \n",
    "\n",
    "# Importance of each predictor.\n",
    "#print(importance(fit,type = 2)) \n",
    "#help randomForest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "\n",
    "#### Example of simple equation\n",
    "\\begin{equation}\n",
    "e = mc^2\n",
    "\\end{equation}\n",
    "\n",
    "#### Example of matrix equation - Cross product formula:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{V}_1 \\times \\mathbf{V}_2 =  \\begin{vmatrix}\n",
    "\\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\\n",
    "\\frac{\\partial X}{\\partial u} &  \\frac{\\partial Y}{\\partial u} & 0 \\\\\n",
    "\\frac{\\partial X}{\\partial v} &  \\frac{\\partial Y}{\\partial v} & 0\n",
    "\\end{vmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "#### Example of multiline equation - The Lorenz Equations:\n",
    "\n",
    "\\begin{align}\n",
    "\\dot{x} & = \\sigma(y-x) \\\\\n",
    "\\dot{y} & = \\rho x - y - xz \\\\\n",
    "\\dot{z} & = -\\beta z + xy\n",
    "\\end{align}\n",
    "\n",
    "#### Example of Markdown Table:\n",
    "\n",
    "| This | is   |\n",
    "|------|------|\n",
    "|   a  | table|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative models\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
